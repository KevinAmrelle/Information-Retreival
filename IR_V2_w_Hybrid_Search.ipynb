{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57c16da1-9448-4916-9728-2caf16d2fced",
   "metadata": {},
   "source": [
    "# IR project v2 with (Optional) Hybrid Search\n",
    "\n",
    "Overview of the Project\n",
    "-Environment Setup\n",
    "\n",
    "-Data Loading and Preprocessing\n",
    "\n",
    "-Generating Embeddings with Vertex AI\n",
    "\n",
    "-Building the Vector Store with FAISS\n",
    "\n",
    "-Implementing the Information Retrieval System\n",
    "\n",
    "-Example Query and Retrieval\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d8861c-d4ca-4896-b9d1-9827fef52692",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. Environment Setup\n",
    "Install Required Libraries\n",
    "Ensure you have the necessary libraries installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609b0a89-17aa-4b33-9086-ffb6e2eb14d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install google-cloud-storage\n",
    "!pip install faiss-cpu\n",
    "!pip install PyPDF2\n",
    "!pip install pandas\n",
    "!pip install scikit-learn  # For TfidfVectorizer\n",
    "!pip install langchain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add417a3-5dab-4b96-93f5-56d8898e06b9",
   "metadata": {},
   "source": [
    "Import necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "241f1beb-f4ff-4252-818e-60241c9377ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from google.cloud import storage\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import faiss\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7539b060-7463-4002-a2ec-a7eec08ddb63",
   "metadata": {},
   "source": [
    "### 2. Data Loading and Preprocessing\n",
    "Download PDF from Google Cloud Storage\n",
    "We start by downloading the PDF file from Google Cloud Storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0079270b-1881-413a-82aa-3da67dbb7bdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download_blob(bucket_name, source_blob_name, destination_file_name):\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(source_blob_name)\n",
    "    try:\n",
    "        blob.download_to_filename(destination_file_name)\n",
    "        print(f\"Downloaded {source_blob_name} to {destination_file_name}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading {source_blob_name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e191b6-2288-4a3f-af9a-e935a710d300",
   "metadata": {},
   "source": [
    "Set your bucket and file names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bfd5516-26c8-4da5-8ae3-0bf018d3aefa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded WF_benefits_book.pdf to /tmp/WF_benefits_book.pdf.\n"
     ]
    }
   ],
   "source": [
    "bucket_name = \"benefit_books_3\"\n",
    "source_blob_name = \"WF_benefits_book.pdf\"\n",
    "destination_file_name = \"/tmp/WF_benefits_book.pdf\"\n",
    "\n",
    "download_blob(bucket_name, source_blob_name, destination_file_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf76406-12e3-4f00-b688-ef0a773fd103",
   "metadata": {},
   "source": [
    "Extract and Preprocess Text\n",
    "Next, we extract text from the PDF and preprocess it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "602c09d0-f477-441c-beeb-3b20a76e4f13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    with open(pdf_path, \"rb\") as file:\n",
    "        reader = PdfReader(file)\n",
    "        if reader.is_encrypted:\n",
    "            try:\n",
    "                reader.decrypt(\"\")\n",
    "            except:\n",
    "                raise ValueError(\"Failed to decrypt PDF file.\")\n",
    "        for page in reader.pages:\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                text += page_text\n",
    "    return text\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Clean up the text\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "raw_text = preprocess_pdf(destination_file_name)\n",
    "clean_text = preprocess_text(raw_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cb1d88-37a2-4a11-8d4d-3066f4290595",
   "metadata": {},
   "source": [
    "Split Text into Chunks\n",
    "We split the text into manageable chunks for embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b0f26b8-1291-4bd2-8114-f2d8a295a9a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = text_splitter.split_text(clean_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda5d8c1-05e5-4a76-a610-7534dddc9e93",
   "metadata": {},
   "source": [
    "Create Document Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1ff7944-b0af-4d41-a10d-cbea8aa6963a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "documents = [Document(page_content=chunk) for chunk in chunks]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510cdce2-559f-4c4a-be58-6fb29bbc3c04",
   "metadata": {},
   "source": [
    "### 3. Generating Embeddings with Vertex AI\n",
    "Initialize the Embedding Model\n",
    "\n",
    "Note: If you are running this in an environment that doesn't require explicit authentication (like Colab with a logged-in account), you don't need to set up GOOGLE_APPLICATION_CREDENTIALS or initialize aiplatform.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1045f87a-315d-4500-a641-2ab3230aadeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from vertexai.preview.language_models import TextEmbeddingModel\n",
    "\n",
    "# Initialize the embedding model\n",
    "embedding_model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko@001\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e141c90-3baf-48e0-b78f-efd3f4a07287",
   "metadata": {
    "tags": []
   },
   "source": [
    "Generate Dense Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8efc3440-6bff-494a-8366-e87db0a9a53c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_dense_embeddings(texts):\n",
    "    embeddings = []\n",
    "    batch_size = 5  # Adjust based on API limits\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        response = embedding_model.get_embeddings(batch_texts)\n",
    "        embeddings.extend([embedding.values for embedding in response])\n",
    "    return embeddings\n",
    "\n",
    "texts = [doc.page_content for doc in documents]\n",
    "dense_embeddings = get_dense_embeddings(texts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cca493-902c-4949-b9f7-67315e30305e",
   "metadata": {},
   "source": [
    "Generate Sparse Embeddings (Optional)\n",
    "Sparse embeddings can be useful for hybrid search.\n",
    "https://github.com/GoogleCloudPlatform/generative-ai/blob/main/embeddings/hybrid-search.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "825d9992-3c7b-4804-bbef-9f7b05828ea3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(texts)\n",
    "\n",
    "def get_sparse_embedding(text):\n",
    "    tfidf_vector = vectorizer.transform([text])\n",
    "    return {\n",
    "        \"values\": tfidf_vector.data.tolist(),\n",
    "        \"dimensions\": tfidf_vector.indices.tolist()\n",
    "    }\n",
    "\n",
    "sparse_embeddings = [get_sparse_embedding(text) for text in texts]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1786285a-a101-4ed3-9084-11bd7dd9d662",
   "metadata": {},
   "source": [
    "### 4. Building the Vector Store with FAISS\n",
    "Initialize FAISS Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6beef3a8-fde3-4ca5-a60e-092bab66c157",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding_dim = len(dense_embeddings[0])  # Should be 768 for 'textembedding-gecko'\n",
    "index = faiss.IndexFlatL2(embedding_dim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec0f04a-dc40-4cda-a585-27de0313ca6a",
   "metadata": {},
   "source": [
    "Add Embeddings to Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60f73fe1-ca34-40d2-b872-0a72b5f1bd5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.array(dense_embeddings).astype('float32')\n",
    "index.add(embedding_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac0e3ca-cb49-406e-9f6b-f5e3419d7765",
   "metadata": {},
   "source": [
    "Save the Index and Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20715c71-43aa-42ba-9a5e-1e6605bc288e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "faiss.write_index(index, 'faiss_index.index')\n",
    "\n",
    "# Save documents and sparse embeddings\n",
    "df = pd.DataFrame({\n",
    "    'content': texts,\n",
    "    'sparse_embedding_values': [emb['values'] for emb in sparse_embeddings],\n",
    "    'sparse_embedding_dims': [emb['dimensions'] for emb in sparse_embeddings]\n",
    "})\n",
    "df.to_csv('documents.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e200eeec-fcb4-4bb9-ac12-c63f9db70eb8",
   "metadata": {},
   "source": [
    "### 5. Implementing the Information Retrieval System\n",
    "Query Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d49278fe-3a59-44fe-ad50-2ba51b345041",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def query_index(query, k=5):\n",
    "    # Generate dense embedding for the query\n",
    "    query_embedding = embedding_model.get_embeddings([query])[0].values\n",
    "    query_vector = np.array([query_embedding]).astype('float32')\n",
    "    \n",
    "    # Generate sparse embedding for the query (optional)\n",
    "    query_sparse_embedding = get_sparse_embedding(query)\n",
    "    \n",
    "    # Search the FAISS index\n",
    "    distances, indices = index.search(query_vector, k)\n",
    "    \n",
    "    # Retrieve the corresponding documents\n",
    "    results = []\n",
    "    for idx in indices[0]:\n",
    "        idx = int(idx)\n",
    "        content = df.iloc[idx]['content']\n",
    "        distance = distances[0][list(indices[0]).index(idx)]\n",
    "        results.append({\n",
    "            'content': content,\n",
    "            'distance': distance,\n",
    "            'sparse_embedding': {\n",
    "                'values': df.iloc[idx]['sparse_embedding_values'],\n",
    "                'dimensions': df.iloc[idx]['sparse_embedding_dims']\n",
    "            }\n",
    "        })\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67b4963a-deb0-49c9-85f4-59b05bf9be73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"What dental benefits are available?\"\n",
    "results = query_index(query, k=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ffe55b7-c208-421d-8695-c3c7684b9764",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 1:\n",
      "Content: 3-4 Cost 3-4 How the Delta Dental coverage options work 3-4 Pretreatment estimate 3-4 What the Delta Dental coverage options cover 3-6 Your dental benefits and costs at a glance 3-6 Frequency limits 3...\n",
      "Distance: 0.4681614339351654\n",
      "\n",
      "Result 2:\n",
      "Content: option 2 Employee Care accepts all relay service calls, including 711. Information about premiums HR Services & Support site Chapter 3: Dental Plan 3-2 The information in this chapter — along with app...\n",
      "Distance: 0.5025160312652588\n",
      "\n",
      "Result 3:\n",
      "Content: eligible covered services and the maximum benefits payable under the plan. “What the Delta Dental coverage options cover” section starting on page 3-6 for detailed benefits and coverage information. Y...\n",
      "Distance: 0.5220946073532104\n",
      "\n",
      "Result 4:\n",
      "Content: and when coverage begins 3-3 Changing or canceling coverage 3-3 When coverage ends 3-4 Cost 3-4 How the Delta Dental coverage options work 3-4 Pretreatment estimate 3-4 What the Delta Dental coverage ...\n",
      "Distance: 0.5399929285049438\n",
      "\n",
      "Result 5:\n",
      "Content: Wachovia Dental Program. The total lifetime orthodontia benefits paid per person, combined with any other orthodontia benefits paid under the Wells Fargo dental plan or the former Wachovia Dental Prog...\n",
      "Distance: 0.5410927534103394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, result in enumerate(results):\n",
    "    print(f\"Result {i+1}:\")\n",
    "    print(f\"Content: {result['content'][:200]}...\")  # Show first 200 characters\n",
    "    print(f\"Distance: {result['distance']}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dd9ba1-f3d3-4d48-968c-52abf8342bb8",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "In this lecture, we've built an IR system that:\n",
    "\n",
    "Processes a PDF from Google Cloud Storage.\n",
    "Splits the text into chunks and preprocesses it.\n",
    "Generates embeddings using Vertex AI's TextEmbeddingModel.\n",
    "Builds a FAISS index for efficient similarity search.\n",
    "Implements a query function to retrieve relevant text based on user input.\n",
    "This system can be extended and integrated into applications where efficient text retrieval is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fa2b00-417b-418c-8e65-ebba45a81374",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m124",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m124"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
